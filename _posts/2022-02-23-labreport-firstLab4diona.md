---
layout: post
title: Lab4 Diona Espinosa
subtitle: ENG 612 Prof.Thomas
cover-img:
thumbnail-img: 
share-img: 
tags: [Lab4, labreport, Voyant]
---

## Voyant prueba


**Work in progress**

1. My science corpus ID: d861c593177d5fc623ed3c1cf04a680d
2. [My Hum corpus address](https://voyant-tools.org/?corpus=867b315d99ab2b60f406f564ff585001&panels=cirrus,reader,trends,summary,contexts)

## Answers to questions:

**1.	How does this change the word cloud, and what are these changes telling you?**
Changing and removing the stopworks from Auto-detected to the option NONE and confirming, what get visually first is a smaller cloud, more compact and homogeneous. Also, what we have is not only visual. In terms of concepts, we are getting connections words mostly prepositions or articles such as "the" or "and". This is contrary to concepts full of meaning that we have using the option "Auto-detected". Voyant automatically excludes stopwords from word frecuency calculation. Instead of saying include this, we stop it.  Now, the word cloud is most stopwords, but in the option "terms" we have a lot of repetition of words that are common in English. That does not give us useful information, relevant to the discussion within the humanities and the use of new documents. Using the Auto-detected option we can get a sense of the topic of the text, a distinctive sense of this collection of text. 

**2.	 Why is relative frequency sometimes a more useful or accurate measure of a term’s importance than raw frequency?**
Relative frequency is useful to find relevant terms within our document because it helps with clusters of repetitions, locating where these occur. This relative frequency can be useful to understand how relevant a term may be in a certain context (or not). Voyant locates the repetition by one million of words. For example, if we consider the case discussed in class about the relative frequency of “MCAS” in the humanities dataset, we can identify that MCAS is certainly the most frequent term, however, frequency does not mean relevance. Voyant is a tool, and like any tool it carries out logical and, in this case, quantitative processes. What we obtain with the relative frequency of MCAS is a high data, but not useful for the semantic or critical analysis of the text (further discussion in next question). On the contrary, the raw frequency provides the number of times that a word is repeated in all the dataset, while the relative frequency pay attention to the use of the term within shorter occurrences (one per million, for example).

**3.	What is this document? And, more importantly, what have you learned about the term “mcas” in our corpus overall, and/or the utility or value of “significance” metrics like TF-IDF?**
This document that contains the term “mcas” repeated 442 times. “MCAS” is actually an acronymous, the school’s abbreviation “Morrissey College of Arts and Sciences Honors”. The term has a lot of repetition because goes after the name of each student or staff member who signed a petition. If we check is the most significant term relative to frequency, but in reality, is not because only happens in one document and it is empty of meaning. It does not have significant content, is only an indicator of the repetition of a term in a corpus. Voyant can read statistically and artificially speaking, as I mentioned above, it is impossible to the tool made a close reading. The latter what tell us is that “significance” metrics correspond to the overall scrutiny of the dataset but does not provide the context within this term is used. As researchers we need to take a close look to the numbers to learn how to read them and analysis them. 

**4.	Looking through this list of terms and their “Comparison” values, what observations can you make about terms that are more likely to occur in the humanities corpus vs. terms that are more likely to occur in the science corpus? How are these terms different?**

**Here's a “Comparison” table:**

| Humanities dataset’s words | Number | Science dataset’s words |Number|
| :------ |:--- | :--- |:---|:---|
| Students| 3359| Said* |2884|
| Said*| 2761 |Science |1677|
| Humanities| 2174 | Research|1341
|*words in common|

If we check the numbers, we can notice the three more statistically relevant terms in both datasets. This first look give us very important information: main topics or concerns within these corpuses.  In the humanities dataset the term more used is “students”, and then we have “said” and “humanities”. Therefore, in the science dataset the second and third terms are “science” and “research”. Then, the word “said” is common for both datasets in terms of high frequency of repetition. However, if we go deeper and sort the terms positively skewed in Humanities, we can notice that the debate is around words like “students”, “faculty”, “courses”. But if we display the numbers in an ascending order, we will notice that “science”, “scientists” or “researchers” are the most common words in the Science dataset, which is not surprising and confirm which are the main topics of interest in one or other field.

**5.	What tool(s) did you explore? What did this tool(s) help you to observe about this data and/or what did you learn about this data using this tool(s)? Alternatively, what did you hope to learn about this data using this tool and how (or why) did reality seem to fall short of that expectation?**

This tool helps me to understand better how statistics can help but not determine the conclusion for research. We need to may a close analysis of context and uses of the data within the text

## Notebook entry

I consider that in general Voyant is a very useful tool for data analysis, and I agree with Katherine Bowes when she said that this one is (or could be) the first step for researchers in Digital Humanities. This lab has show us how a software works in terms of an algorithm, statistically speaking. Voyant becomes an excellent tool for data visualization like graphs, clouds, charts, bubble lines and on and most of them you can customize. It has a clean and simple presentation and accepts different kind of text format, however, always tool effectivity is not equal to quality and innovative approach in research. We learn that the data must be evaluate not only statistically, but also within its context. As Sarah Allison contends at the beginning of her text “every project that uses numbers to make sense of literature seems to teach us again that in digital analysis we create more data than we can ever fully use and therefore understand. And yet, with each new project we produce more. (1)”. The latter Bowes confirms saying in the case of Voyant that “contexts is really helpful. It shows the term, the stuff that appears to the left and right of it in the text, and which text it appears in.” In other words, we, as academics, are encouraged to use the data and analyze it in quantitative and qualitative way, what the raw frequency tell us about a term for example, why is use express it like in the software and how is use it within the text. 